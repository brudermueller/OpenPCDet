{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Dataset-Functions\" data-toc-modified-id=\"Dataset-Functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Dataset Functions</a></span></li><li><span><a href=\"#Visualize-Ground-Truth\" data-toc-modified-id=\"Visualize-Ground-Truth-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Visualize Ground Truth</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Visualize-Sensor-Setup\" data-toc-modified-id=\"Visualize-Sensor-Setup-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Visualize Sensor Setup</a></span></li><li><span><a href=\"#Evaluate-Detections\" data-toc-modified-id=\"Evaluate-Detections-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Evaluate Detections</a></span><ul class=\"toc-item\"><li><span><a href=\"#l1_corner_loss_80epochs\" data-toc-modified-id=\"l1_corner_loss_80epochs-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>l1_corner_loss_80epochs</a></span></li><li><span><a href=\"#jrdb_exp5\" data-toc-modified-id=\"jrdb_exp5-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>jrdb_exp5</a></span></li><li><span><a href=\"#jrdb_exp9_no_aug\" data-toc-modified-id=\"jrdb_exp9_no_aug-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>jrdb_exp9_no_aug</a></span></li><li><span><a href=\"#jrdb_exp10_no_aug\" data-toc-modified-id=\"jrdb_exp10_no_aug-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>jrdb_exp10_no_aug</a></span></li><li><span><a href=\"#jrdb_exp11_no_aug_diff_target_cfg\" data-toc-modified-id=\"jrdb_exp11_no_aug_diff_target_cfg-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>jrdb_exp11_no_aug_diff_target_cfg</a></span></li><li><span><a href=\"#jrdb_exp12_aug_wo_gt_sample\" data-toc-modified-id=\"jrdb_exp12_aug_wo_gt_sample-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>jrdb_exp12_aug_wo_gt_sample</a></span></li><li><span><a href=\"#jrdb_exp17_aug_wo_gt_slow_lr_no_pretrain\" data-toc-modified-id=\"jrdb_exp17_aug_wo_gt_slow_lr_no_pretrain-2.3.7\"><span class=\"toc-item-num\">2.3.7&nbsp;&nbsp;</span>jrdb_exp17_aug_wo_gt_slow_lr_no_pretrain</a></span></li><li><span><a href=\"#jrdb_exp19_aug_wo_gt_no_pretrain_angle_loss\" data-toc-modified-id=\"jrdb_exp19_aug_wo_gt_no_pretrain_angle_loss-2.3.8\"><span class=\"toc-item-num\">2.3.8&nbsp;&nbsp;</span>jrdb_exp19_aug_wo_gt_no_pretrain_angle_loss</a></span></li><li><span><a href=\"#jrdb_exp14_aug_wo_gt_slow_lr\" data-toc-modified-id=\"jrdb_exp14_aug_wo_gt_slow_lr-2.3.9\"><span class=\"toc-item-num\">2.3.9&nbsp;&nbsp;</span>jrdb_exp14_aug_wo_gt_slow_lr</a></span></li><li><span><a href=\"#jrdb_exp23_aug_wo_gt_no_pretrain_corrected_iou\" data-toc-modified-id=\"jrdb_exp23_aug_wo_gt_no_pretrain_corrected_iou-2.3.10\"><span class=\"toc-item-num\">2.3.10&nbsp;&nbsp;</span>jrdb_exp23_aug_wo_gt_no_pretrain_corrected_iou</a></span></li><li><span><a href=\"#jrdb_exp24_aug_wo_gt_no_pretrain_corrected_iou\" data-toc-modified-id=\"jrdb_exp24_aug_wo_gt_no_pretrain_corrected_iou-2.3.11\"><span class=\"toc-item-num\">2.3.11&nbsp;&nbsp;</span>jrdb_exp24_aug_wo_gt_no_pretrain_corrected_iou</a></span></li><li><span><a href=\"#jrdb_exp25_aug_wo_gt_pretrain\" data-toc-modified-id=\"jrdb_exp25_aug_wo_gt_pretrain-2.3.12\"><span class=\"toc-item-num\">2.3.12&nbsp;&nbsp;</span>jrdb_exp25_aug_wo_gt_pretrain</a></span></li><li><span><a href=\"#jrdb_exp30_angle_loss\" data-toc-modified-id=\"jrdb_exp30_angle_loss-2.3.13\"><span class=\"toc-item-num\">2.3.13&nbsp;&nbsp;</span>jrdb_exp30_angle_loss</a></span></li></ul></li></ul></li><li><span><a href=\"#JRDB-Indoor\" data-toc-modified-id=\"JRDB-Indoor-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>JRDB Indoor</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#jrdb_indoor_exp20_aug_wo_gt_no_pretrain_angle_loss\" data-toc-modified-id=\"jrdb_indoor_exp20_aug_wo_gt_no_pretrain_angle_loss-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>jrdb_indoor_exp20_aug_wo_gt_no_pretrain_angle_loss</a></span></li></ul></li></ul></li><li><span><a href=\"#BEV-Plot\" data-toc-modified-id=\"BEV-Plot-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>BEV Plot</a></span></li><li><span><a href=\"#Data-Augmentation\" data-toc-modified-id=\"Data-Augmentation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data Augmentation</a></span></li><li><span><a href=\"#Test-/-Debugging\" data-toc-modified-id=\"Test-/-Debugging-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Test / Debugging</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed this [instruction manual](https://github.com/kuixu/kitti_object_vis/tree/master/jupyter) on how to setup jupyter notebook mayavi interface for remote usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from xvfbwrapper import Xvfb\n",
    "vdisplay = Xvfb(width=1920, height=1080)\n",
    "vdisplay.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "mlab.init_notebook('ipy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import json\n",
    "\n",
    "# general utils \n",
    "from matplotlib.gridspec import GridSpec\n",
    "import visualize_utils as V\n",
    "from pcdet.utils.custom_data_utils import load_h5, load_h5_basic, get_data_files\n",
    "from pcdet.utils.object3d_custom import Object3d\n",
    "from pcdet.utils.box_utils import boxes_to_corners_3d\n",
    "from pcdet.ops.iou3d_nms import iou3d_nms_utils\n",
    "from pcdet.datasets.augmentor import augmentor_utils as aug\n",
    "\n",
    "# jrdb specific functions \n",
    "from pcdet.utils.jrdb_utils import transform_pts_upper_velodyne_to_base, transform_pts_laser_to_base,\\\n",
    "                                   transform_pts_lower_velodyne_to_base, transform_pts_lower_to_upper_velodyne\n",
    "from pcdet.utils import plot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "def get_lidar_pts(idx, split='val'): \n",
    "    if  type(idx) == int: # idx \n",
    "        all_val_files = get_data_files(os.path.join(FILE_PATH, f'{split}.txt'))\n",
    "        lidar_file_upper = DATA_PATH + all_val_files[idx]\n",
    "        print(lidar_file_upper)\n",
    "    elif type(idx) == str: \n",
    "        lidar_file_upper = idx # filename\n",
    "    lidar_file_lower = lidar_file_upper.replace('upper', 'lower') \n",
    "    \n",
    "    pts_upper = np.array(load_h5_basic(lidar_file_upper), dtype=np.float32)\n",
    "    pts_upper[:,:3] = transform_pts_upper_velodyne_to_base(pts_upper[:, 0:3].T).T\n",
    "#     pts_upper[:,3] = minmax_scale(pts_upper[:,3], axis=0)\n",
    "    \n",
    "    pts_lower = np.array(load_h5_basic(lidar_file_lower), dtype=np.float32)\n",
    "    pts_lower[:,:3] = transform_pts_lower_velodyne_to_base(pts_lower[:, 0:3].T).T\n",
    "#     pts_lower[:,3] = minmax_scale(pts_lower[:,3], axis=0)\n",
    "    \n",
    "    pts_merged = np.concatenate((pts_upper, pts_lower), axis=0)\n",
    "    return pts_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def load_json_file(label_file):\n",
    "    \"\"\" Loads json file to a python dictionary.\n",
    "\n",
    "    Args:\n",
    "        label_file: full file path to json file\n",
    "\n",
    "    Returns:\n",
    "        dictionary contained in json file \n",
    "    \"\"\"\n",
    "    with open(label_file) as f:\n",
    "        data = json.load(f)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_all_labels(label_dir): \n",
    "    \"\"\" Load label dict for entire database from json files (one for each recording). \n",
    "    \"\"\"\n",
    "    label_dict = collections.defaultdict(dict)   \n",
    "    num_points_small = 0 \n",
    "    for json_file in os.listdir(label_dir): \n",
    "        sequence = os.path.basename(os.path.splitext(json_file)[0])\n",
    "        file_dict = load_json_file(os.path.join(label_dir, json_file))\n",
    "        for frame, annotations_list in file_dict['labels'].items(): \n",
    "            frame_num = frame.split('.')[0]\n",
    "            box_list = []\n",
    "            for anno in annotations_list: \n",
    "                no_eval = anno['attributes']['no_eval']\n",
    "                if no_eval: \n",
    "                interpolated = anno['attributes']['interpolated']\n",
    "                dist = anno['attributes']['distance']\n",
    "                num_points = anno['attributes']['num_points']\n",
    "#                 if anno['attributes']['num_points']<=5: \n",
    "#                     num_points_small += 0\n",
    "                if not no_eval: \n",
    "                    box_dict = anno['box']\n",
    "                    xyz = np.array([box_dict[\"cx\"], box_dict[\"cy\"], box_dict[\"cz\"]], dtype=np.float32).reshape(1, 3)\n",
    "                    lwh = np.array([box_dict[\"l\"], box_dict[\"w\"], box_dict[\"h\"]], dtype=np.float32).reshape(1, 3)\n",
    "                    box = np.concatenate([xyz, \n",
    "                                          lwh, \n",
    "                                          np.reshape(box_dict['rot_z'], (-1,1)), \n",
    "                                          np.reshape(float(dist), (-1,1)), \n",
    "                                          np.reshape(float(num_points), (-1,1))], axis=1)\n",
    "                    box_list.append(box)\n",
    "            label_dict[sequence][frame_num] = box_list \n",
    "    return label_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_label(frame, label_dict, box_object=False, return_dist=False):\n",
    "    \"\"\" \n",
    "    Return bbox annotations per frame, defined as (N,7), i.e. (N x [x, y, z, h, w, l, ry])\n",
    "\n",
    "    Args:\n",
    "        frame (string): frame id \n",
    "    \"\"\"\n",
    "    file_parts = frame.split('/')\n",
    "    sequence = file_parts[len(file_parts)-2]   \n",
    "    frame_num = file_parts[-1].split('.')[0]\n",
    "    print('Sequence: {}, Frame: {}'.format(sequence, frame_num))\n",
    "    try: \n",
    "        gt_info = np.reshape(label_dict[sequence][frame_num],(-1,9))\n",
    "        bbox_list = gt_info[:,:7] \n",
    "    except KeyError: \n",
    "        print(\"Label dict does not contain key combination (seq: {}, frame_num: {})\".format(sequence, frame_num))\n",
    "        return None\n",
    "    if box_object: \n",
    "        bbox_obj_list = [Object3d(box, gt=True) for box in bbox_list]\n",
    "        return bbox_obj_list\n",
    "    else: \n",
    "        if return_dist: \n",
    "            return bbox_list, gt_info[:,7], gt_info[:,8]\n",
    "        else: \n",
    "            return bbox_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def visualize_pts(pts, fig=None, bgcolor=(0, 0, 0), color=(1.0, 1.0, 1.0),\n",
    "                  show_intensity=False, size=(600, 600), draw_origin=True):\n",
    "    if not isinstance(pts, np.ndarray):\n",
    "        pts = pts.cpu().numpy()\n",
    "    if fig is None:\n",
    "        fig = mlab.figure(figure=None, bgcolor=bgcolor, engine=None, size=size)\n",
    "\n",
    "    if show_intensity:\n",
    "        G = mlab.points3d(pts[:, 0], pts[:, 1], pts[:, 2], pts[:, 3], mode='point',\n",
    "                          colormap='gnuplot', scale_factor=1, figure=fig)\n",
    "    else:\n",
    "        G = mlab.points3d(pts[:, 0], pts[:, 1], pts[:, 2], mode='point',\n",
    "                          color=color, scale_factor=1, figure=fig)\n",
    "    if draw_origin:\n",
    "        mlab.points3d(0, 0, 0, color=(1, 1, 1), mode='cube', scale_factor=0.2)\n",
    "        mlab.plot3d([0, 1.0], [0, 0], [0, 0], color=(1, 0, 0), tube_radius=0.025)\n",
    "        mlab.plot3d([0, 0], [0, 1.0], [0, 0], color=(0, 1, 0), tube_radius=0.025)\n",
    "        mlab.plot3d([0, 0], [0, 0], [0, 1.0], color=(0, 0, 1), tube_radius=0.025)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_pts_lower_upper_from_file(f): \n",
    "    print(\"Loading data from: {}\".format(f))\n",
    "    f1 = f.replace('upper', 'lower') \n",
    "    \n",
    "    pts_upper = np.array(load_h5_basic(f), dtype=np.float32)\n",
    "    pts_upper[:,:3] = transform_pts_upper_velodyne_to_base(pts_upper[:, 0:3].T).T\n",
    "\n",
    "    pts_lower = np.array(load_h5_basic(f1), dtype=np.float32)\n",
    "    pts_lower[:,:3] = transform_pts_lower_velodyne_to_base(pts_lower[:, 0:3].T).T\n",
    "\n",
    "    return pts_lower, pts_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def read_annotations(label_path):    \n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    content = [line.strip().split(' ') for line in lines]\n",
    "    bboxes = np.vstack(\n",
    "        [np.array((float(det[2]), float(det[3]), float(det[4]), # x,y,z\n",
    "                   float(det[7]), float(det[6]), float(det[5]), # w,l,h\n",
    "                   float(det[8])), dtype=np.float32) for det in content]) # rz\n",
    "    scores = [float(det[-1]) for det in content]\n",
    "    return bboxes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def evaluate_detections(idx, epoch, experiment, val_tag, ax_lims=None, bgcolor=(0.,0.,0.), \\\n",
    "                        add_scores=True, show_img=False, save_name=None, mask_distance=False, \n",
    "                       eval_all=False):\n",
    "    \n",
    "    all_val_files = get_data_files(os.path.join(FILE_PATH, 'val.txt'))\n",
    "    print('Total number of evaluation instances: {}'.format(len(all_val_files)))\n",
    "    frame_file = os.path.join(DATA_PATH, all_val_files[idx])\n",
    "    \n",
    "    pts_lidar = get_lidar_pts(idx)\n",
    "    gt_boxes, distances, num_pts = get_label(frame_file, label_dict, return_dist=True)\n",
    "    if mask_distance:\n",
    "        dist_mask = distances > 7\n",
    "        num_pts_mask = num_pts < 5\n",
    "    else: \n",
    "        dist_mask = None\n",
    "        num_pts_mask = None \n",
    "    print(np.sum(dist_mask))\n",
    "    if show_img: \n",
    "        img = get_image(frame_file)\n",
    "    else: \n",
    "        img=None\n",
    "    if eval_all: \n",
    "        bboxes3d_path = os.path.join(OUTPUT_PATH, \n",
    "                                     \"{}/eval/eval_all_default/{}/epoch_{}/val/final_result/data/{}.txt\"\\\n",
    "                                     .format(experiment,val_tag, epoch, idx))\n",
    "    else: \n",
    "        bboxes3d_path = os.path.join(OUTPUT_PATH, \n",
    "                                     \"{}/eval/epoch_{}/val/{}/final_result/data/{}.txt\"\\\n",
    "                                     .format(experiment,epoch,val_tag, idx))\n",
    "        \n",
    "    print('Ground Truth Boxes: \\n - path: {}\\n - shape: {}'.format(frame_file, gt_boxes.shape))\n",
    "        \n",
    "    det_boxes, scores = read_annotations(bboxes3d_path)\n",
    "    \n",
    "#     center_depth = np.linalg.norm(det_boxes[:, 0:3], axis=1)\n",
    "#     det_ignore_mask = center_depth > 7\n",
    "    det_ignore_mask = None\n",
    "    \n",
    "    if not add_scores: scores=None\n",
    "    print('Det_Boxes: \\n - path: {}\\n - shape: {}'.format(bboxes3d_path, det_boxes.shape))\n",
    "    \n",
    "    fig = V.draw_scenes(pts_lidar, gt_boxes=gt_boxes, ref_boxes=det_boxes, \\\n",
    "                        ref_scores=None, ref_labels=None, bgcolor=bgcolor, scores=scores, \\\n",
    "                        dist_mask=dist_mask, num_pts_mask=num_pts_mask, det_ignore_mask=det_ignore_mask)\n",
    "    \n",
    "    _plot_sequence(pts_lidar, gt_boxes, idx, det_boxes=det_boxes, image=img, \n",
    "                   show_intensity=False, save_name=save_name, ax_limits=ax_lims)\n",
    "    if save_name: \n",
    "        mlab.savefig(filename=os.path.join('../../','plots/results/{}.png'.format(save_name)))        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dets(idx, epoch, experiment, val_tag): \n",
    "    all_val_files = get_data_files(os.path.join(FILE_PATH, 'val.txt'))\n",
    "    print('Total number of evaluation instances: {}'.format(len(all_val_files)))\n",
    "    frame_file = os.path.join(DATA_PATH, all_val_files[idx])\n",
    "    \n",
    "    pts_lidar = get_lidar_pts(idx)\n",
    "    gt_boxes = get_label(frame_file, label_dict, return_dist=False)\n",
    "    \n",
    "    bboxes3d_path = os.path.join(OUTPUT_PATH, \n",
    "                                 \"{}/eval/epoch_{}/val/{}/final_result/data/{}.txt\"\\\n",
    "                                 .format(experiment,epoch,val_tag, idx))\n",
    "\n",
    "    print('Ground Truth Boxes: \\n - path: {}\\n - shape: {}'.format(frame_file, gt_boxes.shape))\n",
    "        \n",
    "    det_boxes, _ = read_annotations(bboxes3d_path)\n",
    "    return pts_lidar, gt_boxes, det_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_tp_mask_from_overlaps(pred_boxes, gt_boxes): \n",
    "    \"\"\"\n",
    "    Returns a dict with keys = iou thresholds and the corresponding value a boolean mask \n",
    "    indicating if the overlap between predictions and ground truth exceeds the given threshold -> true positive. \n",
    "    \n",
    "    \"\"\"\n",
    "    iou_thresholds = np.arange(0.3, 0.9, 0.05)\n",
    "    pred_boxes = torch.from_numpy(pred_boxes).contiguous().cuda(non_blocking=True).float()\n",
    "    gt_boxes = torch.from_numpy(gt_boxes).contiguous().cuda(non_blocking=True).float()\n",
    "    iou3d = iou3d_nms_utils.boxes_iou3d_gpu(pred_boxes, gt_boxes)  # (M, N)\n",
    "    max_iou, gt_ind  = torch.max(iou3d, dim=1) # max_overlaps, gt_assignment\n",
    "\n",
    "    mask_dict = {}\n",
    "    for iou in iou_thresholds: \n",
    "        assigned_gt_box_idx = []\n",
    "        true_positive_mask = []\n",
    "        for el in zip(max_iou,gt_ind): \n",
    "            if el[0].item() > iou and el[1].item() not in assigned_gt_box_idx: \n",
    "                true_positive_mask.append(1.0)\n",
    "            else: \n",
    "                true_positive_mask.append(0.0)\n",
    "            \n",
    "        true_positive_mask = (max_iou > iou).float().cpu().numpy()\n",
    "        mask_dict[iou] = true_positive_mask\n",
    "    return mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def _load_image(file):\n",
    "    \"\"\"Load an image given file url.\n",
    "\n",
    "    Returns:\n",
    "        im (np.ndarray[H, W, 3]): (H, W) = (480, 3760) for stitched image,\n",
    "            (480, 752) for individual image\n",
    "    \"\"\"\n",
    "    assert os.path.exists(file)\n",
    "    im = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    return im\n",
    "\n",
    "def get_image(file): \n",
    "    file_parts = file.split('/')\n",
    "    sequence = file_parts[len(file_parts)-2]   \n",
    "    frame_num = file_parts[-1].split('.')[0]\n",
    "    return _load_image(os.path.join(IM_PATH, sequence, frame_num+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def draw_bev(corners, ax, c=\"red\"):\n",
    "    # side and back boarder\n",
    "    xy = corners[[0,3, 2,1],:2]\n",
    "    ax.plot(xy[:,0], xy[:,1], c=c, linestyle=\"-\")\n",
    "    # front boarder\n",
    "    xy = corners[[0, 1], :2]\n",
    "    ax.plot(xy[:,0], xy[:,1], c=c, linestyle=\"--\")\n",
    "\n",
    "def _plot_sequence(pts_lidar,  gt_boxes, frame, det_boxes=None, image=None, \n",
    "                   show_intensity=False, save_name=None, auto_save=False, \n",
    "                   ax_limits=None):\n",
    "    plt.rc('xtick',labelsize=14)\n",
    "    plt.rc('ytick',labelsize=14)\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    if image is None: \n",
    "        gs = GridSpec(1, 2, figure=fig)\n",
    "    else: \n",
    "        # image\n",
    "        gs = GridSpec(2, 2, figure=fig)\n",
    "        ax_im = fig.add_subplot(gs[1, :])\n",
    "        ax_im.cla()\n",
    "        ax_im.axis(\"off\")\n",
    "        ax_im.imshow(image)\n",
    "\n",
    "    ax_bev = fig.add_subplot(gs[0, 0])\n",
    "    ax_bev_zoom = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    color_pool = np.random.uniform(size=(100, 3))\n",
    "    corners_lidar = boxes_to_corners_3d(gt_boxes, rot_mat_alt=True)\n",
    "    if det_boxes is not None: \n",
    "        corners_lidar_det = boxes_to_corners_3d(det_boxes, rot_mat_alt=True)\n",
    "        \n",
    "    if type(frame) == str: \n",
    "        frame_name = '/'.join(frame.split('/')[-2:])\n",
    "        auto_save_name = str(frame_name.replace('/','_').replace('.h5', '.png')) \n",
    "    else: \n",
    "        frame_name = f'sample_idx_{frame}'\n",
    "        auto_save_name = frame_name + '.png'\n",
    "    # BEV\n",
    "    for ax in [ax_bev, ax_bev_zoom]: \n",
    "        ax.cla()\n",
    "        ax.set_xlabel(\"x [m]\", fontsize=18)\n",
    "        ax.set_ylabel(\"y [m]\", fontsize=18)\n",
    "        if show_intensity:\n",
    "            ax.scatter(pts_lidar[:,0], pts_lidar[:,1], s=1, c=pts_lidar[:,3], cmap='viridis')\n",
    "        else: \n",
    "            ax.scatter(pts_lidar[:,0], pts_lidar[:,1], s=1, c='b')\n",
    "        for i in range(corners_lidar.shape[0]):\n",
    "            corners_lidar2d = corners_lidar[i, :4, :2]\n",
    "            draw_bev(corners_lidar2d, ax, c='r') # c=color_pool[i]\n",
    "        if det_boxes is not None: \n",
    "            for i in range(corners_lidar_det.shape[0]):\n",
    "                corners_lidar2d_det = corners_lidar_det[i, :4, :2]\n",
    "                draw_bev(corners_lidar2d_det, ax, c='g')\n",
    "    \n",
    "    ax_bev.set_title(f\"Frame: {frame_name}\", fontsize=18)\n",
    "    ax_bev_zoom.set_title(f\"Frame zoomed: {frame_name}\", fontsize=18)\n",
    "    \n",
    "    if ax_limits is not None: \n",
    "        ax_bev.set_xlim(*ax_limits[0])\n",
    "        ax_bev.set_ylim(*ax_limits[1])\n",
    "        ax_bev_zoom.set_xlim(*ax_limits[2])\n",
    "        ax_bev_zoom.set_ylim(*ax_limits[3])\n",
    "    else: \n",
    "        ax_bev.set_xlim(-40,40)\n",
    "        ax_bev.set_ylim(-40,40)\n",
    "        ax_bev_zoom.set_xlim(-15,15)\n",
    "        ax_bev_zoom.set_ylim(-15,15)\n",
    "    \n",
    "    plot_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "    if save_name:  \n",
    "        plot_dir = os.path.join(plot_dir, \"../plots/results/\", save_name+'_bev.pdf')\n",
    "        print(f\"Saving to {plot_dir}\")\n",
    "        plt.savefig(plot_dir, bbox_inches='tight')  \n",
    "    elif auto_save: \n",
    "        plot_dir = os.path.join(plot_dir, \"../plots/\", auto_save_name)\n",
    "        print(f\"Saving to {plot_dir}\")\n",
    "        plt.savefig(plot_dir, bbox_inches='tight') \n",
    "    else: \n",
    "        print(\"Did not save figure. Add filename in arguments to be able to save figure.\")\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ignore_labels(label_dir): \n",
    "    '''\n",
    "    Returns a dict with keys (sequence, frame_id) saving a boolean value if this data instance should be \n",
    "    ignored or not. \n",
    "    '''\n",
    "    label_dict = collections.defaultdict(dict)\n",
    "    for json_file in os.listdir(label_dir): \n",
    "        sequence = os.path.basename(os.path.splitext(json_file)[0])\n",
    "        file_dict = load_json_file(os.path.join(label_dir, json_file))\n",
    "        for frame, annotations_list in file_dict['labels'].items(): \n",
    "            print(frame)\n",
    "            print(len(annotations_list))\n",
    "            ignore_mask = np.zeros(len(annotations_list), dtype=bool)\n",
    "            frame_num = frame.split('.')[0]\n",
    "            for i, anno in enumerate(annotations_list): \n",
    "                dist = anno['attributes']['distance']\n",
    "                num_points = anno['attributes']['num_points']\n",
    "                if num_points <= 5 and dist > 7:\n",
    "                    ignore_mask[i] = 1\n",
    "            label_dict[sequence][frame_num] = ignore_mask \n",
    "            print(ignore_mask.shape)\n",
    "            print(ignore_mask)\n",
    "        break\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Ground Truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation vectors evaluated for transformations\n",
    "_T_camera_to_base = np.array([0.019685, 0, -0.742092], dtype=np.float32).reshape(1, 3)\n",
    "_T_upper_lidar_to_base = np.array([0.019685, 0, -1.077382], dtype=np.float32).reshape(1, 3) # from calib file, actually to rgb \n",
    "_T_camera_to_upper_lidar = np.array([0,0,1.077382-0.742092], dtype=np.float32).reshape(1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Relevant Paths to extract data\n",
    "FILE_PATH = os.path.join('../../', 'data/jrdb/')\n",
    "DATA_PATH = '/hdd/master_lara_data/JRDB/cvgl/group/jrdb/data'\n",
    "LABEL_PATH = os.path.join(DATA_PATH, 'train_dataset', 'labels', 'labels_3d')\n",
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn/') # model detections \n",
    "split = 'train'\n",
    "IM_PATH = os.path.join(DATA_PATH, f'{split}_dataset/images/image_stitched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate dict containing all labels for all train/val sequences\n",
    "label_dict = get_all_labels(LABEL_PATH)\n",
    "print(label_dict.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file to anaylze\n",
    "\n",
    "# f = '/hdd/master_lara_data/JRDB/cvgl/group/jrdb/data/train_dataset/pointclouds/hdf5/upper_velodyne/jordan-hall-2019-04-22_0/000012.h5'                                                                                                                                                                                                                                              \n",
    "# f = '/hdd/master_lara_data/JRDB/cvgl/group/jrdb/data/train_dataset/pointclouds/hdf5/upper_velodyne/bytes-cafe-2019-02-07_0/000012.h5'                                                                                                                                                                                                                                              \n",
    "\n",
    "idx = 4000\n",
    "split='val'\n",
    "split_dir = f'../../data/jrdb/{split}.txt'\n",
    "current_samples = [x.strip() for x in open(split_dir).readlines()]\n",
    "f = DATA_PATH + current_samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label,dist,num_pts= get_label(f, label_dict, return_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sensor Setup \n",
    "Upper sensor points shown in green, lower sensor points shown in red "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_coor_lower, pts_coor_upper = get_pts_lower_upper_from_file(f)\n",
    "gt_boxes = get_label(f, label_dict)\n",
    "gt_corners3d = boxes_to_corners_3d(gt_boxes, rot_mat_alt=True)\n",
    "print('Num ground truth objects: {}'.format(gt_boxes.shape[0]))\n",
    "fig = None\n",
    "bg_col = (0.0,0.0,0.0)\n",
    "fig = visualize_pts(pts_coor_upper, bgcolor=bg_col, color=(0.0, 1.0, 0.0), show_intensity=False, size=(1000,600)) # green\n",
    "fig = visualize_pts(pts_coor_lower, fig=fig, bgcolor=bg_col, color=(1.0, 0.0, 0.0), show_intensity=False, size=(1000,600)) # red \n",
    "fig = V.draw_corners3d(gt_corners3d, fig=fig, color=(0, 0, 1), max_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pts_tot = pts_coor_lower.shape[0] + pts_coor_upper.shape[0]\n",
    "print(num_pts_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4000\n",
    "pts = get_lidar_pts(idx)\n",
    "bg_col = (1.0,1.0,1.0)\n",
    "fig = visualize_pts(pts, bgcolor=bg_col, color=(0.0, 1.0, 0.0), show_intensity=True, size=(1000,600)) # green\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'jrdb_test_plot_lidar'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frame id \n",
    "idx = 1200\n",
    "val_tag = 'jrdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_lims = [\n",
    "    [-15, 15], # x\n",
    "    [-15, 15], # y\n",
    "    [-7.5, 7.5], # x zoomed\n",
    "    [-7.5, 7.5]  # y zoomed\n",
    "]\n",
    "# bgcolor =  (1.,1.,1.) #(.75,.75,.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### l1_corner_loss_80epochs \n",
    "Model trained on custom dataset, evaluated on JRDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 80\n",
    "experiment = 'l1_corner_loss_80epochs'\n",
    "OUTPUT_PATH = os.path.join('../../', 'output/custom_models/pointrcnn/') # model detections \n",
    "fig = None\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "name=None\n",
    "fig = evaluate_detections(idx, epoch, experiment, val_tag, save_name=name, ax_lims=ax_lims, mask_distance=True)#, bgcolor=bgcolor)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = name+ '_1'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### jrdb_exp5 \n",
    "Model trained with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "experiment = 'jrdb_exp5'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "fig = evaluate_detections(idx, epoch, experiment, val_tag, save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = name+ '_1'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### jrdb_exp9_no_aug\n",
    "Model trained without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = 27\n",
    "experiment = 'jrdb_exp9_no_aug'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = name+ '_1'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### jrdb_exp10_no_aug\n",
    "Model trained without data augmentation, compared to exp 9 there parameters in the target config (FG_THRESH, BG_THRESH) have been tuned/changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = 23\n",
    "experiment = 'jrdb_exp10_no_aug'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name += '_1'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### jrdb_exp11_no_aug_diff_target_cfg\n",
    "Model trained without data augmentation, compared to exp 9 there parameters in the target config (FG_THRESH, BG_THRESH) have been tuned/changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "epoch = 9\n",
    "experiment = 'jrdb_exp11_no_aug_diff_target_cfg'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name += '_1'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### jrdb_exp12_aug_wo_gt_sample\n",
    "Trained with data augmentation (random world flips and scaling, but _no_ gt sampling). Learning rate has been increased again to initial value. Experiments before conducted with reduced LR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/') # model detections \n",
    "epoch = 23\n",
    "experiment = 'jrdb_exp12_aug_wo_gt_sample'\n",
    "val_tag = 'jrdb'\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### jrdb_exp17_aug_wo_gt_slow_lr_no_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn_no_pretrained/') # model detections \n",
    "epoch = 23\n",
    "experiment = 'jrdb_exp17_aug_wo_gt_slow_lr_no_pretrain'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name += '_1'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jrdb_exp19_aug_wo_gt_no_pretrain_angle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn_no_pretrained/') # model detections \n",
    "epoch = 19\n",
    "experiment = 'jrdb_exp19_aug_wo_gt_no_pretrain_angle_loss'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name +='_1'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jrdb_exp14_aug_wo_gt_slow_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4000\n",
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn_iou_jrdb/') # model detections \n",
    "epoch = 10\n",
    "experiment = 'jrdb_exp14_aug_wo_gt_slow_lr_iou_cls_score'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jrdb_exp23_aug_wo_gt_no_pretrain_corrected_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn_no_pretrained/') # model detections \n",
    "epoch = 30\n",
    "experiment = 'jrdb_exp23_aug_wo_gt_no_pretrain_corrected_iou'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "# name=None\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jrdb_exp24_aug_wo_gt_no_pretrain_corrected_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=5500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn_no_pretrained/') # model detections \n",
    "epoch = 30\n",
    "experiment = 'jrdb_exp24_aug_wo_gt_no_pretrain_corrected_iou'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx {}_{}_{}_epoch{}_unconstraint'.format(idx, experiment, val_tag, epoch)\n",
    "name=None\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims) #, mask_distance=True) #, bgcolor=bgcolor)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'idx {}_{}_{}_epoch{}_unconstraint'.format(idx, experiment, val_tag, epoch)\n",
    "name +='_1'\n",
    "mlab.savefig(filename=os.path.join('../../','plots/{}.png'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jrdb_exp25_aug_wo_gt_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx= 2833\n",
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn/') # model detections \n",
    "epoch = 30\n",
    "experiment = 'jrdb_exp25_aug_wo_gt_pretrain'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "# name=None\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jrdb_exp30_angle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx= 20\n",
    "idx = 4000\n",
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn_angle_loss/') # model detections \n",
    "epoch = 30\n",
    "experiment = 'jrdb_exp30_angle_loss'\n",
    "val_tag = 'jrdb'\n",
    "name = 'idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "# name=None\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JRDB Indoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frame id \n",
    "idx = 500\n",
    "val_tag = 'jrdb'\n",
    "ax_lims = [\n",
    "    [-15, 15], # x\n",
    "    [-15, 15], # y\n",
    "    [-7.5, 7.5], # x zoomed\n",
    "    [-7.5, 7.5]  # y zoomed\n",
    "]\n",
    "bgcolor = (.75,.75,.75) #(1.,1.,1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant Paths to extract data\n",
    "FILE_PATH = os.path.join('../../', 'data/jrdb_indoor/')\n",
    "DATA_PATH = '/hdd/master_lara_data/JRDB/cvgl/group/jrdb/data'\n",
    "LABEL_PATH = os.path.join(DATA_PATH, 'train_dataset', 'labels', 'labels_3d')\n",
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn/') # model detections \n",
    "split = 'val'\n",
    "IM_PATH = os.path.join(DATA_PATH, f'{split}_dataset/images/image_stitched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jrdb_indoor_exp20_aug_wo_gt_no_pretrain_angle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn_no_pretrained/') # model detections \n",
    "epoch = 13\n",
    "experiment = 'jrdb_indoor_exp20_aug_wo_gt_no_pretrain_angle_loss'\n",
    "val_tag = 'jrdb'\n",
    "name = 'indoor_idx{}_{}_{}_epoch{}'.format(idx, experiment, val_tag, epoch)\n",
    "# name=None\n",
    "fig2 = evaluate_detections(idx, epoch, experiment, val_tag,save_name=name, ax_lims=ax_lims, mask_distance=True, eval_all=True)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEV Plot\n",
    "Create plots from scene in birds eye view (BEV). It can also include the \"stitched\" image from the camera sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = get_lidar_pts(f)\n",
    "img = get_image(f)\n",
    "gt_boxes = get_label(f, label_dict)\n",
    "print(f'Number of persons in frame: {gt_boxes.shape[0]}')\n",
    "corners_lidar = V.boxes_to_corners_3d(gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_sequence(pts, gt_boxes, f,image=img, save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=None\n",
    "fig_dets = V.draw_scenes(pts, gt_boxes=gt_boxes,ref_boxes=None, ref_scores=None, ref_labels=None)\n",
    "fig_dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('xtick',labelsize=14)\n",
    "plt.rc('ytick',labelsize=14)\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs = GridSpec(1, 2, figure=fig)\n",
    "\n",
    "ax_bev1 = fig.add_subplot(gs[0, 0])\n",
    "ax_bev2 = fig.add_subplot(gs[0, 1])\n",
    "idx = 1800\n",
    "epoch = 30\n",
    "val_tag = 'jrdb'\n",
    "\n",
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/pointrcnn_no_pretrained/') # model detections \n",
    "exp1 = 'jrdb_exp24_aug_wo_gt_no_pretrain_corrected_iou'\n",
    "pts_lidar1, gt_boxes1, det_boxes1 = return_dets(idx, epoch, exp1, val_tag)\n",
    "\n",
    "OUTPUT_PATH = os.path.join('../../', 'output/jrdb_models/') # model detections \n",
    "exp2= 'jrdb_exp30_angle_loss'\n",
    "pts_lidar2, gt_boxes2, det_boxes2 = return_dets(idx, epoch, exp2, val_tag)\n",
    "\n",
    "corners_lidar1 = boxes_to_corners_3d(gt_boxes1, rot_mat_alt=True)\n",
    "corners_lidar2 = boxes_to_corners_3d(gt_boxes2, rot_mat_alt=True)\n",
    "\n",
    "corners_lidar_det1 = boxes_to_corners_3d(det_boxes1, rot_mat_alt=True)\n",
    "corners_lidar_det2 = boxes_to_corners_3d(det_boxes2, rot_mat_alt=True)\n",
    "\n",
    "axes = [ax_bev1, ax_bev2]\n",
    "dets = [corners_lidar_det1, corners_lidar_det2]\n",
    "labels = [corners_lidar1, corners_lidar2]\n",
    "pts = [pts_lidar1, pts_lidar2]\n",
    "\n",
    "for ax, det, label in zip(axes, dets, labels): \n",
    "    ax.cla()\n",
    "    ax.set_xlabel(\"x [m]\", fontsize=18)\n",
    "    ax.set_ylabel(\"y [m]\", fontsize=18)\n",
    "    ax.scatter(pts_lidar1[:,0], pts_lidar1[:,1], s=1, c='b')\n",
    "    for i in range(label.shape[0]):\n",
    "        corners_lidar2d = label[i, :4, :2]\n",
    "        draw_bev(corners_lidar2d, ax, c='r')\n",
    "        \n",
    "    for i in range(det.shape[0]):\n",
    "        corners_lidar2d_det = det[i, :4, :2]\n",
    "        draw_bev(corners_lidar2d_det, ax, c='g')\n",
    "    \n",
    "    ax.set_xlim(-10,10)\n",
    "    ax.set_ylim(-8,8)\n",
    "\n",
    "ax_bev1.set_title(\"Experiment without angle encoding\", fontsize=18)\n",
    "ax_bev2.set_title(\"Experiment with angle encoding\", fontsize=18)\n",
    "\n",
    "plot_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "plot_dir = os.path.join(plot_dir, \"../plots/\", f'idx_{idx}_angle_comparison_bev.pdf')\n",
    "print(f\"Saving to {plot_dir}\")\n",
    "plt.savefig(plot_dir, bbox_inches='tight')  \n",
    "\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "Test and visualize augmentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1000\n",
    "f = DATA_PATH + current_samples[idx]\n",
    "pts_lidar = get_lidar_pts(idx, split='train')\n",
    "gt_boxes = get_label(f, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = None\n",
    "fig = V.draw_scenes(pts_lidar, gt_boxes=gt_boxes,ref_boxes=None, ref_scores=None, ref_labels=None, show_intensity=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_lims = [\n",
    "    [-20, 20], # x\n",
    "    [-20, 20], # y\n",
    "    [-10,  5], # x zoomed\n",
    "    [-10, 10]  # y zoomed\n",
    "]\n",
    "fig=None\n",
    "_plot_sequence(pts_lidar, gt_boxes, f,image=None, save_fig=False, ax_limits=ax_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random flip around x \n",
    "gt_box_aug, pts_aug = aug.random_flip_along_x(gt_boxes, pts_lidar)\n",
    "_plot_sequence(pts_aug, gt_box_aug, f,image=None, save_fig=False, ax_limits=ax_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random world rotation\n",
    "rot_angle_range= [-0.78539816, 0.78539816]\n",
    "gt_box_aug, pts_aug = aug.global_rotation(gt_box_aug, pts_aug, rot_range=rot_angle_range, rot_mat_alt=True)\n",
    "_plot_sequence(pts_aug, gt_box_aug, f,image=None, save_fig=False, ax_limits=ax_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random scaling \n",
    "scale_range = [0.95, 1.05]\n",
    "gt_box_aug, pts_aug = aug.global_scaling(gt_box_aug, pts_aug, scale_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_sequence(pts_aug, gt_box_aug, f,image=None, save_fig=False, ax_limits=ax_lims)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.567px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}